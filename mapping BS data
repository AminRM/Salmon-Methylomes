#Step1: Split the fastq samples into N files and align them in parallel to faster this time-consuming step:

#!/bin/bash
#SBATCH --job-name=split
#SBATCH --nodes=1
#SBATCH --mail-type=ALL
#SBATCH --mem=6gb
#SBATCH --time=24:00:00
#SBATCH --mail-user=amin.esmai@csiro.au

split -l 80000000 A_OV_T4F4_val_R1.fq OV_T4F4_val_R1
split -l 80000000 A_OV_T4F4_val_R2.fq OV_T4F4_val_R2
split -l 80000000 A_OV_T1F3_val_R1.fq OV_T1F3_val_R1
split -l 80000000 A_OV_T1F3_val_R2.fq OV_T1F3_val_R2
split -l 80000000 A_LV_T1F4_val_R1.fq LV_T1F4_val_R1
split -l 80000000 A_LV_T1F4_val_R2.fq LV_T1F4_val_R2
split -l 80000000 Pit_T1F3_val_R1.fq Pit_T1F3_val_R1
split -l 80000000 Pit_T1F3_val_R2.fq Pit_T1F3_val_R2
split -l 80000000 Pit_T4F2_val_R1.fq Pit_T4F2_val_R1
split -l 80000000 Pit_T4F2_val_R2.fq Pit_T4F2_val_R2

#Step2: prepare reference for mapping 

cat index-bsseeker.sh
#!/bin/bash
#SBATCH --job-name=2index-ref
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=4
#SBATCH --mail-type=ALL
#SBATCH --mem=8gb
#SBATCH --time=10:00:00
#SBATCH --mail-user=amin.esmai@csiro.au
$SLURM_SUBMIT_DIR

module load python
module load bowtie/2.2.9/
python BSseeker2-master/bs_seeker2-build.py -f GCA_000233375.4_ICSASG_v2_genomic.fna --aligner bowtie2


#Step3: map all the samples using that bash script and save that as map-bsseeker.sh
#!/bin/bash
#SBATCH --job-name=x
#SBATCH --nodes=1
#SBATCH --cpus-per-task=8
#SBATCH --mail-type=ALL
#SBATCH --mem=12gb
#SBATCH --time=24:00:00
#SBATCH --mail-user=amin.esmai@csiro.au
$SLURM_SUBMIT_DIR

module load python/2.7.13
module load bowtie/2.2.9/
python /flush2/moh034/BSseeker2-master/bs_seeker2-align.py -1 /flush1/moh034/WGBS/OV_T1F1_val_R1aa.fq -2 /flush1/moh034/WGBS/OV_T1F1_val_R2aa.fq --aligner bowtie2 --bt2-p 4 -g GCA_000233375.4_ICSASG_v2_genomic.fna -f bam -o OV-T1F1-aa.bam -u unmapped-aa

in the terminal type: sbatch map-bsseeker.sh 

#Step4: merge bam files for each sample and sort
#!/bin/bash
#SBATCH --job-name=OV-T1F1-MS
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=4
#SBATCH --mail-type=ALL
#SBATCH --mem=12gb
#SBATCH --time=24:00:00
#SBATCH --mail-user=amin.esmai@csiro.au
$SLURM_SUBMIT_DIR

module load samtools/1.9.0
samtools merge -@ ${SLURM_NTASKS} OV-T1F1_merged.bam OV-T1F1-aa.bam OV-T1F1-ab.bam OV-T1F1-ac.bam OV-T1F1-ad.bam OV-T1F1-ae.bam
samtools sort -@ ${SLURM_NTASKS} -T temp -O BAM OV-T1F1_merged.bam -o OV-T1F1_merged_sorted.bam

#Step5: check and remove PCR duplicates 

#!/bin/bash
#SBATCH --job-name=OV-T4F4-pcr
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=4
#SBATCH --mail-type=ALL
#SBATCH --mem=40gb
#SBATCH --time=24:00:00
#SBATCH --mail-user=amin.esmai@csiro.au
$SLURM_SUBMIT_DIR
module load jemalloc
export OMP_NUM_THREADS=$SLURM_NTASKS_PER_NODE
module load picard
java -Xmx8g -jar /flush2/moh034/picard.jar MarkDuplicates I=OV-T4F4_merged_sorted.bam O=OV-T4F4_filtered.bam M=dup_metrics.txt REMOVE_DUPLICATES=true AS=true SORTING_COLLECTION_SIZE_RATIO=0.10

Step6: methylation caling within BS-Seeker2

(base) moh034@pearcey-login:/flush2/moh034/OV-T4F4> cat OV-T4F4-MCall.sh
#!/bin/bash
#SBATCH --job-name=OV-T4F4-MCall
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --mail-type=ALL
#SBATCH --mem=4gb
#SBATCH --time=24:00:00
#SBATCH --mail-user=amin.esmai@csiro.au
$SLURM_SUBMIT_DIR

module load python/2.7.13
python /flush2/moh034/BSseeker2-master/bs_seeker2-call_methylation.py -i OV-T4F4_filtered.bam --sorted -o OV-T4F4 --db /flush2/moh034/BSseeker2-master/bs_utils/reference_genomes/GCA_000233375.4_ICSASG_v2_genomic.fna_bowtie2





